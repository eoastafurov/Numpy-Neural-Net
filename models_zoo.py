from typing import Optional, Type, Any
import numpy as np

from core.activations.activations import ReLU, LogSoftMax
from core.base.module import Module
from core.layers.linear import Linear
from core.layers.dropout import Dropout
from core.layers.batch_norm import BatchNormalization
from core.models.sequential import Sequential


class Zoo:
    @staticmethod
    def auto(
            input_dim: int,
            out_dim: int,
            Activation: Type[Module],
            softmax: Any,
            bn: bool,
            dp: bool,
            depth: Optional[int] = 10,
    ) -> Sequential:
        dims = list(
            reversed(
                np.linspace(start=out_dim, stop=input_dim, num=depth).astype(int)
            )
        )
        model_ = Sequential(name='AutoGenerated')

        layers = np.array([
            Linear(in_features=dims[i], out_features=dims[i + 1])
            for i in range(len(dims) - 1)
        ]).reshape(-1, 1)
        activations = np.array(
            [Activation() for _ in range(len(layers))]
        ).reshape(-1, 1)

        _lb = 1
        if bn:
            b_norms = np.array(
                [BatchNormalization(name='BatchNorm{}'.format(i)) for i in range(len(layers))]
            ).reshape(-1, 1)
            layers = np.concatenate((layers, b_norms, activations), axis=1)
            _lb += 1
        else:
            layers = np.concatenate((layers, activations), axis=1)

        if dp:
            dropout = np.array(
                [Dropout(p=0.3) for _ in range(len(layers))]
            ).reshape(-1, 1) if dp else None
            layers = np.concatenate((layers, dropout), axis=1)
            _lb += 1

        layers = layers.reshape(-1)[:-_lb]
        model_.add(list(layers) + [softmax])

        return model_


# model = Zoo.auto(input_dim=3072, out_dim=10, Activation=ReLU, softmax=LogSoftMax(), bn=True, dp=True, depth=4)
